"""Add element count to pools

Revision ID: 197e2575b90d
Revises: 90330c1045b2
Create Date: 2021-09-06 00:27:04.194895

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '197e2575b90d'
down_revision = '90330c1045b2'
branch_labels = None
depends_on = None


# Table definitions
t_pool = sa.Table(
    'pool',
    sa.MetaData(),
    sa.Column('id', sa.Integer),
    sa.Column('element_count', sa.Integer),
)

t_pool_element = sa.Table(
    'pool_element',
    sa.MetaData(),
    sa.Column('id', sa.Integer()),
    sa.Column('pool_id', sa.Integer()),
)

t_similarity_pool = sa.Table(
    'similarity_pool',
    sa.MetaData(),
    sa.Column('id', sa.Integer),
    sa.Column('element_count', sa.Integer),
)

t_similarity_pool_element = sa.Table(
    'similarity_pool_element',
    sa.MetaData(),
    sa.Column('id', sa.Integer()),
    sa.Column('pool_id', sa.Integer()),
)


def upgrade(engine_name):
    globals()["upgrade_%s" % engine_name]()


def downgrade(engine_name):
    globals()["downgrade_%s" % engine_name]()


def upgrade_():
    # Add column, must be nullable initially unless a server default is set
    with op.batch_alter_table('pool', schema=None) as batch_op:
        batch_op.add_column(sa.Column('element_count', sa.Integer(), nullable=True))

    # Data migration
    print("Migrating prebooru table data")
    connection = op.get_bind()
    pool_results = connection.execute(sa.select([
        t_pool.c.id,
        ])).fetchall()
    for (pool_id,) in pool_results:
        pool_count = connection.execute(sa.select([sa.func.count()]).select_from(t_pool_element).where(t_pool_element.c.pool_id == pool_id)).scalar()
        connection.execute(t_pool.update().where(t_pool.c.id == pool_id).values(
            element_count=pool_count,
            ))

    # Set the column to non-null
    with op.batch_alter_table('pool', schema=None) as batch_op:
        batch_op.alter_column('element_count',
               existing_type=sa.INTEGER(),
               nullable=False)


def downgrade_():
    with op.batch_alter_table('pool', schema=None) as batch_op:
        batch_op.drop_column('element_count')


def upgrade_cache():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade_cache():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def upgrade_similarity():
    # Add column, must be nullable initially unless a server default is set
    with op.batch_alter_table('similarity_pool', schema=None) as batch_op:
        batch_op.add_column(sa.Column('element_count', sa.Integer(), nullable=True))

    # Data migration
    print("Migrating similarity table data")
    connection = op.get_bind()
    pool_results = connection.execute(sa.select([
        t_similarity_pool.c.id,
        ])).fetchall()
    for index, (pool_id,) in enumerate(pool_results):
        if (index % 1000) == 0:
            print(index, '/', len(pool_results))
        pool_count = connection.execute(sa.select([sa.func.count()]).select_from(t_similarity_pool_element).where(t_similarity_pool_element.c.pool_id == pool_id)).scalar()
        connection.execute(t_similarity_pool.update().where(t_similarity_pool.c.id == pool_id).values(
            element_count=pool_count,
            ))

    # Set the column to non-null
    with op.batch_alter_table('similarity_pool', schema=None) as batch_op:
        batch_op.alter_column('element_count',
               existing_type=sa.INTEGER(),
               nullable=False)


def downgrade_similarity():
    with op.batch_alter_table('similarity_pool', schema=None) as batch_op:
        batch_op.drop_column('element_count')
